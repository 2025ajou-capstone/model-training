{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OpWtZgFgG11G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6430a355-5ecb-4526-928a-c2d553a8aec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF-_AOUJpstx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09945e46-5959-45c2-ae32-85e3d78a513b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics\n",
        "!pip install -q albumentations==1.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/drive/MyDrive/Ajou_ISE/4á„’á…¡á†¨á„‚á…§á†«_1á„’á…¡á†¨á„€á…µ/B105-1 á„‹á…²á†¼á„’á…¡á†¸á„‰á…µá„‰á…³á„á…¦á†·á„€á…©á†¼á„’á…¡á†¨á„Œá…©á†¼á„’á…¡á†¸á„‰á…¥á†¯á„€á…¨/training_dataset/250610-test.zip\"\n"
      ],
      "metadata": {
        "id": "PuSIdWuDINg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train \\\n",
        "  model='/content/drive/MyDrive/Ajou_ISE/4á„’á…¡á†¨á„‚á…§á†«_1á„’á…¡á†¨á„€á…µ/B105-1 á„‹á…²á†¼á„’á…¡á†¸á„‰á…µá„‰á…³á„á…¦á†·á„€á…©á†¼á„’á…¡á†¨á„Œá…©á†¼á„’á…¡á†¸á„‰á…¥á†¯á„€á…¨/training_dataset/250610_best2.pt' \\\n",
        "  data='./data.yaml' \\\n",
        "  epochs=100 batch=8 imgsz=1280 plots=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gJI1FsUTBkP",
        "outputId": "371ac4ab-6693-471e-b46e-09e0e5273fa1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.152 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/Ajou_ISE/4á„’á…¡á†¨á„‚á…§á†«_1á„’á…¡á†¨á„€á…µ/B105-1 á„‹á…²á†¼á„’á…¡á†¸á„‰á…µá„‰á…³á„á…¦á†·á„€á…©á†¼á„’á…¡á†¨á„Œá…©á†¼á„’á…¡á†¸á„‰á…¥á†¯á„€á…¨/training_dataset/250610_best2.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 86.5MB/s]\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    822117  ultralytics.nn.modules.head.Detect           [7, [128, 256, 512]]          \n",
            "YOLO11s summary: 181 layers, 9,430,501 parameters, 9,430,485 gradients, 21.6 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 391MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 983, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 797, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\", line 227, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\", line 348, in _do_train\n",
            "    self._setup_train(world_size)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\", line 285, in _setup_train\n",
            "    self.amp = torch.tensor(check_amp(self.model), device=self.device)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/utils/checks.py\", line 782, in check_amp\n",
            "    assert amp_allclose(YOLO(\"yolo11n.pt\"), im)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/utils/checks.py\", line 770, in amp_allclose\n",
            "    a = m(batch, imgsz=imgsz, device=device, verbose=False)[0].boxes.data  # FP32 inference\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 185, in __call__\n",
            "    return self.predict(source, stream, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 555, in predict\n",
            "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
            "                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\", line 227, in __call__\n",
            "    return list(self.stream_inference(source, model, *args, **kwargs))  # merge list of Result into one\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 36, in generator_context\n",
            "    response = gen.send(None)\n",
            "               ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\", line 308, in stream_inference\n",
            "    self.model.warmup(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/nn/autobackend.py\", line 846, in warmup\n",
            "    import torchvision  # noqa (import here so torchvision import time not recorded in postprocess time)\n",
            "    ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/ops/roi_align.py\", line 7, in <module>\n",
            "    from torch._dynamo.utils import is_compile_supported\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
            "    from . import convert_frame, eval_frame, resume_execution\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n",
            "    from torch._dynamo.symbolic_convert import TensorifyState\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 27, in <module>\n",
            "    from torch._dynamo.exc import TensorifyScalarRestartAnalysis\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\", line 11, in <module>\n",
            "    from .utils import counters\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\", line 66, in <module>\n",
            "    import torch.fx.experimental.symbolic_shapes\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 74, in <module>\n",
            "    from torch.utils._sympy.functions import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_sympy/functions.py\", line 18, in <module>\n",
            "    import sympy\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/__init__.py\", line 173, in <module>\n",
            "    from .solvers import (solve, solve_linear_system, solve_linear_system_LU,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/solvers/__init__.py\", line 17, in <module>\n",
            "    from .diophantine import diophantine\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/solvers/diophantine/__init__.py\", line 1, in <module>\n",
            "    from .diophantine import diophantine, classify_diop, diop_solve\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sympy/solvers/diophantine/diophantine.py\", line 29, in <module>\n",
            "    from sympy.solvers.solveset import solveset_real\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "cFIP9O-MTejh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7bd4d0-7978-4e7c-8738-2f080d8f8100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml  README.roboflow.txt  \u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  yolo11n.pt\n",
            "\u001b[01;34mdrive\u001b[0m/     \u001b[01;34mruns\u001b[0m/                \u001b[01;34mtest\u001b[0m/         \u001b[01;34mvalid\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/runs/detect/train/weights/best.pt \\\n",
        "     /content/drive/MyDrive/Ajou_ISE/4á„’á…¡á†¨á„‚á…§á†«_1á„’á…¡á†¨á„€á…µ/250610_best2.pt\n"
      ],
      "metadata": {
        "id": "pajfV6AAK8EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ ê²€ì¦\n",
        "!yolo task=detect mode=val \\\n",
        "  model='/content/drive/MyDrive/Ajou_ISE/4á„’á…¡á†¨á„‚á…§á†«_1á„’á…¡á†¨á„€á…µ/250610_best3.pt' \\\n",
        "  data='/content/data.yaml' split=test save_json=True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO2sFZ6dbMx2",
        "outputId": "bbd8e13c-8877-4c16-de8b-280137985285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.152 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLO11s summary (fused): 100 layers, 9,415,509 parameters, 0 gradients, 21.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2542.9Â±473.8 MB/s, size: 119.0 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/test/labels... 25 images, 0 backgrounds, 0 corrupt: 100% 25/25 [00:00<00:00, 1166.41it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/test/labels.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.01it/s]\n",
            "                   all         25         90      0.814      0.718      0.807      0.541\n",
            "                   Car         24         40      0.948      0.975       0.97      0.815\n",
            "          Number_Plate         13         17      0.867       0.77      0.903      0.412\n",
            "      Traffic_Light_Go          8         18          1      0.584       0.85      0.501\n",
            "Traffic_Light_Go_and_Left          2          5      0.954        0.8      0.938      0.489\n",
            "    Traffic_Light_Stop          2          8          1      0.894      0.995      0.578\n",
            "Traffic_Light_Stop_and_Left          1          1      0.927          1      0.995      0.995\n",
            "    Traffic_Light_Wait          1          1          0          0          0          0\n",
            "Speed: 7.1ms preprocess, 9.5ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
            "Saving runs/detect/val/predictions.json...\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}